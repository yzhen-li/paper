
\chapter{Introduction}

To simplify modeling procedures, traditional statistical machine learning (ML) methods are always based on two assumptions about the data. One assumption is that all the instances have the same set of attributes and can be represented as feature vectors all of the same dimensionality. Data represented in this form are referred to as
\emph{flat data} or \emph{propositional data}~\cite{book/srl07}. The other assumption is the
so-called i.i.d.\ assumption, which means that the instances are
assumed to be independent and identically distributed~(i.i.d.). \footnote{We use the terms `instances', `entities' and `objects' interchangeably throughout this thesis.}

However, these two assumptions in traditional ML are unreasonable for \emph{relational data}~\cite{book/srl07} in which the instances are linked (i.e., related) to each other. \emph{Statistical relational learning} (SRL) \cite{book/srl07}, which tries to perform learning and inference from relational data, has attracted many researchers' interests recently due to its wide applications. This thesis focuses on SRL problems.

In the following content of this chapter, we first introduce some basic concepts about relational data and SRL. Then, we present the motivation and summarize the main contributions of this thesis. Finally, we outline the organization of the whole thesis.





\section{Thesis Outline}

The rest of this thesis is organized as follows:

Chapter \ref{chap:background} introduces some background knowledge, including a brief literature review of SRL, traditional latent factor models \cite{book/lvmfa}, and matrix variate distributions \cite{book/matrixdistribution}.

%Chapter \ref{chap:rfm} introduces our new SRL framework, called \emph{relational factor modeling}, including its model formulation and specifications.
Chapter \ref{chap:rrmf} presents the RRMF model, including its model formulation, parameter learning and experimental results on real applications.

Chapter \ref{chap:prpca} presents the PRPCA model, including its model formulation, parameter learning, and experimental performance on linked-document classification.

Chapter \ref{chap:sprp} introduces the sparse version of PRPCA, called SPRP, which can learn interpretable results for relational dimensionality reduction.



Chapter \ref{chap:lwp} introduces the LWP model, including its model formulation, parameter learning and experimental results.

Chapter \ref{chap:glfm} presents the GLFM model to enhance homophily modeling in MLFM. Application to social community detection is also demonstrated.

Chapter \ref{chap:conclusion} concludes the whole thesis and proposes several potential directions for future pursuit.

